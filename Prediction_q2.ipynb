{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3eb557a",
   "metadata": {},
   "source": [
    "# Milestone 1 - Introduction to Buisness Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57964620",
   "metadata": {},
   "source": [
    "Group:\n",
    "\n",
    "Ashish Rakesh Chandra Kukreti (s230134), Ashutosh Dhaka (s222374), Daniel Lihotsk√Ω (s231868), Natsuki Sato (s231459) and Oskar Fusager (s204383)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e98c1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3037790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Trips_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b68bf6",
   "metadata": {},
   "source": [
    "# datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "176b7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['starttime'] = pd.to_datetime(df['starttime'])\n",
    "df['stoptime'] = pd.to_datetime(df['stoptime'])\n",
    "\n",
    "df['start_date'] = df['starttime'].dt.date\n",
    "df['stop_date'] = df['stoptime'].dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824218\n",
      "10530\n",
      "387467\n",
      "12611\n",
      "393570\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "def detect_outliers(data,feature):\n",
    "    Q1=data[feature].quantile(0.25)\n",
    "    Q3=data[feature].quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "    outlier_threshold_low=Q1-1.5*IQR\n",
    "    outlier_threshold_high=Q3+1.5*IQR\n",
    "    outliers=(data[feature]<outlier_threshold_low)|(data[feature]>outlier_threshold_high)\n",
    "    return outliers\n",
    " \n",
    "outliers_trip_minutes=detect_outliers(df,'tripduration')\n",
    "outliers_start_lat=detect_outliers(df,'start_station_latitude')\n",
    "outliers_start_long=detect_outliers(df,'start_station_longitude')\n",
    "outliers_end_lat=detect_outliers(df,'end_station_latitude')\n",
    "outliers_end_long=detect_outliers(df,'end_station_longitude')\n",
    " \n",
    "print(outliers_trip_minutes.sum())\n",
    "print(outliers_start_lat.sum())\n",
    "print(outliers_start_long.sum())\n",
    "print(outliers_end_lat.sum())\n",
    "print(outliers_end_long.sum())\n",
    "\n",
    "all_outliers=outliers_trip_minutes|outliers_start_lat|outliers_start_long|outliers_end_lat|outliers_end_long\n",
    "dfc=df[~all_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735\n",
      "735\n",
      "Common start and end stations: 734\n",
      "stations in start and not in end stations: 1\n",
      "stations in end and not in start stations: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "start_coordinates=dfc[['start_station_latitude','start_station_longitude']]\n",
    " \n",
    "end_coordinates=dfc[['end_station_latitude','end_station_longitude']]\n",
    " \n",
    "list1=list(zip(start_coordinates[\"start_station_latitude\"].values,start_coordinates[\"start_station_longitude\"].values))\n",
    "unique_start=set(list1)\n",
    "print(len(unique_start))\n",
    " \n",
    "list2=list(zip(end_coordinates[\"end_station_latitude\"].values,end_coordinates[\"end_station_longitude\"].values))\n",
    "unique_end=set(list2)\n",
    "print(len(unique_end))\n",
    " \n",
    "list_coordinates=list(set(unique_start|unique_end))\n",
    "len(list_coordinates)\n",
    " \n",
    "intersection = list(set(list1) & set(list2))\n",
    "print(\"Common start and end stations:\",len(intersection))\n",
    "start_notend = list(set(list1) - set(list2))\n",
    "print(\"stations in start and not in end stations:\",len(start_notend))\n",
    "end_notstart = list(set(list2) - set(list1))\n",
    "print(\"stations in end and not in start stations:\",len(end_notstart))\n",
    " \n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = np.array(list_coordinates)\n",
    " \n",
    "scaler=StandardScaler()\n",
    "clustering_data_scaled=scaler.fit_transform(data)\n",
    "km1 = KMeans(n_clusters=30,random_state=42)\n",
    "km1 = km1.fit(clustering_data_scaled)\n",
    "clusters=km1.labels_\n",
    " \n",
    "mapping={}\n",
    " \n",
    "for i,j in enumerate(list_coordinates):\n",
    "    mapping[j]=clusters[i]\n",
    "list_start_cluster = [None] * len(start_coordinates)  # Initialize the list with None or any default value\n",
    " \n",
    "for i, j in enumerate(list1):\n",
    "    if j in mapping:\n",
    "        list_start_cluster[i] = mapping[j]\n",
    "list_end_cluster = [None] * len(end_coordinates)  # Initialize the list with None or any default value\n",
    " \n",
    "for i, j in enumerate(list2):\n",
    "    if j in mapping:\n",
    "        list_end_cluster[i] = mapping[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/gccqklrn6191b9htzpsnct140000gn/T/ipykernel_88684/2332986753.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfc[\"start_cluster_labels\"]=pd.DataFrame(list_start_cluster)\n"
     ]
    }
   ],
   "source": [
    "dfc[\"start_cluster_labels\"]=pd.DataFrame(list_start_cluster)\n",
    "dfc[\"end_cluster_labels\"]=pd.DataFrame(list_end_cluster)\n",
    " \n",
    "max_demand_cluster=dfc[\"start_cluster_labels\"].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating the data\n",
    "\n",
    "First we filter the whole dataset to only include trips that start in the cluster with the highest demand. This is the cluster we will be working with for the prediction challenge. Next we use the trip data from January till October (included) based on starttime to define our training set. For the test set we do the same but for the remaining months of November and December and we differentiate pickups and dropoffs because we want to predict them separately.\n",
    "\n",
    "After that we count the number of trips for each hour and each day of the training set.\n",
    "\n",
    "You can see how the dataframe looks like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/gccqklrn6191b9htzpsnct140000gn/T/ipykernel_88684/94779663.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['hour'] = train['starttime'].dt.hour\n",
      "/var/folders/50/gccqklrn6191b9htzpsnct140000gn/T/ipykernel_88684/94779663.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['date'] = train['starttime'].dt.date\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7255</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>19</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7256</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>20</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7257</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>21</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7258</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>22</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>23</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7260 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  hour  counts\n",
       "0     2018-01-01     0       9\n",
       "1     2018-01-01     1      23\n",
       "2     2018-01-01     2      10\n",
       "3     2018-01-01     3       9\n",
       "4     2018-01-01     4       3\n",
       "...          ...   ...     ...\n",
       "7255  2018-10-31    19     303\n",
       "7256  2018-10-31    20     224\n",
       "7257  2018-10-31    21     150\n",
       "7258  2018-10-31    22     123\n",
       "7259  2018-10-31    23      83\n",
       "\n",
       "[7260 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = dfc[dfc['start_cluster_labels'] == max_demand_cluster] #df1 is the dataframe for the cluster with most pickups\n",
    "\n",
    "#separating train and test data\n",
    "train = df1[df1['starttime'].dt.month <= 10] \n",
    "test_pickups = df1[df1['starttime'].dt.month > 10]\n",
    "test_dropoffs = df1[df1['stoptime'].dt.month > 10]\n",
    "\n",
    "#sum the number of trips of each our of each day\n",
    "train['hour'] = train['starttime'].dt.hour\n",
    "train['date'] = train['starttime'].dt.date\n",
    "train = train.groupby(['date', 'hour']).size().reset_index(name='counts')\n",
    "train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "First we add all of the needed f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>counts</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag-1</th>\n",
       "      <th>lag-2</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7253</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>17</td>\n",
       "      <td>462</td>\n",
       "      <td>451.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7254</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>18</td>\n",
       "      <td>428</td>\n",
       "      <td>462.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7255</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>19</td>\n",
       "      <td>303</td>\n",
       "      <td>428.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7256</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>20</td>\n",
       "      <td>224</td>\n",
       "      <td>303.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7257</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>21</td>\n",
       "      <td>150</td>\n",
       "      <td>224.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7256 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  hour  counts   lag1   lag2  lag-1  lag-2  month  day  \\\n",
       "2     2018-01-01     2      10   23.0    9.0    9.0    3.0      1    1   \n",
       "3     2018-01-01     3       9   10.0   23.0    3.0    2.0      1    1   \n",
       "4     2018-01-01     4       3    9.0   10.0    2.0    2.0      1    1   \n",
       "5     2018-01-01     5       2    3.0    9.0    2.0    5.0      1    1   \n",
       "6     2018-01-01     6       2    2.0    3.0    5.0   15.0      1    1   \n",
       "...          ...   ...     ...    ...    ...    ...    ...    ...  ...   \n",
       "7253  2018-10-31    17     462  451.0  387.0  428.0  303.0     10   31   \n",
       "7254  2018-10-31    18     428  462.0  451.0  303.0  224.0     10   31   \n",
       "7255  2018-10-31    19     303  428.0  462.0  224.0  150.0     10   31   \n",
       "7256  2018-10-31    20     224  303.0  428.0  150.0  123.0     10   31   \n",
       "7257  2018-10-31    21     150  224.0  303.0  123.0   83.0     10   31   \n",
       "\n",
       "      dayofweek  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "5             0  \n",
       "6             0  \n",
       "...         ...  \n",
       "7253          2  \n",
       "7254          2  \n",
       "7255          2  \n",
       "7256          2  \n",
       "7257          2  \n",
       "\n",
       "[7256 rows x 10 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neural_network\n",
    "\n",
    "#add features to our train data\n",
    "train['lag1'] = train['counts'].shift(1)\n",
    "train['lag2'] = train['counts'].shift(2)\n",
    "train['lag-1'] = train['counts'].shift(-1)\n",
    "train['lag-2'] = train['counts'].shift(-2)\n",
    "train['month'] = pd.to_datetime(train['date']).dt.month\n",
    "train['day'] = pd.to_datetime(train['date']).dt.day\n",
    "train['dayofweek'] = pd.to_datetime(train['date']).dt.dayofweek\n",
    "train = train.dropna()\n",
    "\n",
    "#sepereate features from target\n",
    "x = train[['hour', 'lag1', 'lag2', 'lag-1', 'lag-2', 'month', 'day', 'dayofweek']]\n",
    "y = train['counts']\n",
    "\n",
    "#train the model\n",
    "model = neural_network.MLPRegressor()\n",
    "model.fit(x, y)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random day: 2018-11-03\n",
      "r2 score for pickups: 0.909426892218552\n",
      "r2 score for dropoffs: 0.923632921679419\n",
      "mse for pickups: 3260.5356462051095\n",
      "mse for dropoffs: 2783.901250324709\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_Pickups</th>\n",
       "      <th>Predicted_Pickups</th>\n",
       "      <th>Actual_Dropoffs</th>\n",
       "      <th>Predicted_Dropoffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>65.594279</td>\n",
       "      <td>78</td>\n",
       "      <td>70.987298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>29.452541</td>\n",
       "      <td>41</td>\n",
       "      <td>31.471629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>14.296279</td>\n",
       "      <td>20</td>\n",
       "      <td>15.909085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2.261931</td>\n",
       "      <td>12</td>\n",
       "      <td>4.173101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>3.602091</td>\n",
       "      <td>5</td>\n",
       "      <td>1.701261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>6.761075</td>\n",
       "      <td>19</td>\n",
       "      <td>5.110866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>30.938249</td>\n",
       "      <td>28</td>\n",
       "      <td>26.618758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76</td>\n",
       "      <td>83.601676</td>\n",
       "      <td>69</td>\n",
       "      <td>67.746214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>145</td>\n",
       "      <td>154.781349</td>\n",
       "      <td>120</td>\n",
       "      <td>135.235548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>272</td>\n",
       "      <td>210.075077</td>\n",
       "      <td>233</td>\n",
       "      <td>201.446809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>361</td>\n",
       "      <td>285.764292</td>\n",
       "      <td>366</td>\n",
       "      <td>269.740216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>459</td>\n",
       "      <td>351.822489</td>\n",
       "      <td>427</td>\n",
       "      <td>325.173896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>443</td>\n",
       "      <td>475.099993</td>\n",
       "      <td>436</td>\n",
       "      <td>479.424984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>572</td>\n",
       "      <td>408.465956</td>\n",
       "      <td>487</td>\n",
       "      <td>401.080008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>555</td>\n",
       "      <td>567.159632</td>\n",
       "      <td>640</td>\n",
       "      <td>523.802513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>499</td>\n",
       "      <td>433.562389</td>\n",
       "      <td>488</td>\n",
       "      <td>463.118546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>441</td>\n",
       "      <td>538.573523</td>\n",
       "      <td>481</td>\n",
       "      <td>487.678071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>336</td>\n",
       "      <td>392.682220</td>\n",
       "      <td>365</td>\n",
       "      <td>455.133209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>268</td>\n",
       "      <td>320.131895</td>\n",
       "      <td>270</td>\n",
       "      <td>339.746674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>201</td>\n",
       "      <td>242.106815</td>\n",
       "      <td>226</td>\n",
       "      <td>253.304539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>156</td>\n",
       "      <td>193.225863</td>\n",
       "      <td>158</td>\n",
       "      <td>214.447950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>116</td>\n",
       "      <td>145.828806</td>\n",
       "      <td>121</td>\n",
       "      <td>144.434997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>82</td>\n",
       "      <td>131.001289</td>\n",
       "      <td>89</td>\n",
       "      <td>136.244267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>42</td>\n",
       "      <td>93.491806</td>\n",
       "      <td>46</td>\n",
       "      <td>94.897169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual_Pickups  Predicted_Pickups  Actual_Dropoffs  Predicted_Dropoffs\n",
       "0               78          65.594279               78           70.987298\n",
       "1               30          29.452541               41           31.471629\n",
       "2               17          14.296279               20           15.909085\n",
       "3                9           2.261931               12            4.173101\n",
       "4                8           3.602091                5            1.701261\n",
       "5               21           6.761075               19            5.110866\n",
       "6               27          30.938249               28           26.618758\n",
       "7               76          83.601676               69           67.746214\n",
       "8              145         154.781349              120          135.235548\n",
       "9              272         210.075077              233          201.446809\n",
       "10             361         285.764292              366          269.740216\n",
       "11             459         351.822489              427          325.173896\n",
       "12             443         475.099993              436          479.424984\n",
       "13             572         408.465956              487          401.080008\n",
       "14             555         567.159632              640          523.802513\n",
       "15             499         433.562389              488          463.118546\n",
       "16             441         538.573523              481          487.678071\n",
       "17             336         392.682220              365          455.133209\n",
       "18             268         320.131895              270          339.746674\n",
       "19             201         242.106815              226          253.304539\n",
       "20             156         193.225863              158          214.447950\n",
       "21             116         145.828806              121          144.434997\n",
       "22              82         131.001289               89          136.244267\n",
       "23              42          93.491806               46           94.897169"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#pick a random day from the test set\n",
    "random_day = random.choice(pd.date_range(start='2018-11-01', end='2018-12-31'))\n",
    "day_to_predict = random_day + pd.DateOffset(days=1)\n",
    "print('random day:', random_day.date())\n",
    "\n",
    "#pickups and dropoffs for the day to predict grouped by hour (targets)\n",
    "y_test_pickups = test_pickups[test_pickups['starttime'].dt.date == day_to_predict.date()].groupby(test_pickups['starttime'].dt.hour).size().reset_index(name='counts')\n",
    "y_test_dropoffs = test_dropoffs[test_dropoffs['stoptime'].dt.date == day_to_predict.date()].groupby(test_dropoffs['stoptime'].dt.hour).size().reset_index(name='counts')\n",
    "\n",
    "#pickups and dropoffs for the random day grouped by hour(features)\n",
    "x_test_pickups = test_pickups[test_pickups['starttime'].dt.date == random_day.date()].groupby(test_pickups['starttime'].dt.hour).size().reset_index(name='counts')\n",
    "x_test_dropoffs = test_dropoffs[test_dropoffs['stoptime'].dt.date == random_day.date()].groupby(test_dropoffs['stoptime'].dt.hour).size().reset_index(name='counts')\n",
    "\n",
    "#rename columns\n",
    "y_test_pickups = y_test_pickups.rename(columns={'starttime': 'hour'})\n",
    "y_test_dropoffs = y_test_dropoffs.rename(columns={'stoptime': 'hour'})\n",
    "\n",
    "x_test_pickups = x_test_pickups.rename(columns={'starttime': 'hour'})\n",
    "x_test_dropoffs = x_test_dropoffs.rename(columns={'stoptime': 'hour'})\n",
    "\n",
    "#fill in missing hours (where the count is 0)\n",
    "all_hours = pd.DataFrame({'hour': range(24)})\n",
    "\n",
    "y_test_pickups = all_hours.merge(y_test_pickups, on='hour', how='left')\n",
    "y_test_pickups['counts'].fillna(0, inplace=True)\n",
    "y_test_dropoffs = all_hours.merge(y_test_dropoffs, on='hour', how='left')\n",
    "y_test_dropoffs['counts'].fillna(0, inplace=True)\n",
    "\n",
    "x_test_pickups = all_hours.merge(x_test_pickups, on='hour', how='left')\n",
    "x_test_pickups['counts'].fillna(0, inplace=True)\n",
    "x_test_dropoffs = all_hours.merge(x_test_dropoffs, on='hour', how='left')\n",
    "x_test_dropoffs['counts'].fillna(0, inplace=True)\n",
    "\n",
    "#add features to our test set\n",
    "x_test_pickups = pd.concat([x_test_pickups.tail(2), x_test_pickups, x_test_pickups.head(2)])\n",
    "x_test_pickups['lag1'] = x_test_pickups['counts'].shift(1)\n",
    "x_test_pickups['lag2'] = x_test_pickups['counts'].shift(2)\n",
    "x_test_pickups['lag-1'] = x_test_pickups['counts'].shift(-1)\n",
    "x_test_pickups['lag-2'] = x_test_pickups['counts'].shift(-2)\n",
    "x_test_pickups['month'] = random_day.month\n",
    "x_test_pickups['day'] = random_day.day\n",
    "x_test_pickups['dayofweek'] = random_day.dayofweek\n",
    "x_test_pickups = x_test_pickups.dropna()\n",
    "\n",
    "x_test_dropoffs = pd.concat([x_test_dropoffs.tail(2), x_test_dropoffs, x_test_dropoffs.head(2)])\n",
    "x_test_dropoffs['lag1'] = x_test_dropoffs['counts'].shift(1)\n",
    "x_test_dropoffs['lag2'] = x_test_dropoffs['counts'].shift(2)\n",
    "x_test_dropoffs['lag-1'] = x_test_dropoffs['counts'].shift(-1)\n",
    "x_test_dropoffs['lag-2'] = x_test_dropoffs['counts'].shift(-2)\n",
    "x_test_dropoffs['month'] = random_day.month\n",
    "x_test_dropoffs['day'] = random_day.day\n",
    "x_test_dropoffs['dayofweek'] = random_day.dayofweek\n",
    "x_test_dropoffs = x_test_dropoffs.dropna()\n",
    "\n",
    "#separate columns for predicting\n",
    "x_test_pickups = x_test_pickups[['hour', 'lag1', 'lag2', 'lag-1', 'lag-2', 'month', 'day', 'dayofweek']]\n",
    "y_test_pickups = y_test_pickups['counts'].values\n",
    "\n",
    "x_test_dropoffs = x_test_dropoffs[['hour', 'lag1', 'lag2', 'lag-1', 'lag-2', 'month', 'day', 'dayofweek']]\n",
    "y_test_dropoffs = y_test_dropoffs['counts'].values\n",
    "\n",
    "#predict\n",
    "y_pred_pickups = model.predict(x_test_pickups)\n",
    "y_pred_dropoffs = model.predict(x_test_dropoffs)\n",
    "\n",
    "#evaluate\n",
    "r2_pickups = r2_score(y_test_pickups, y_pred_pickups)\n",
    "r2_dropoffs = r2_score(y_test_dropoffs, y_pred_dropoffs)\n",
    "mse_pickups = mean_squared_error(y_test_pickups, y_pred_pickups)\n",
    "mse_dropoffs = mean_squared_error(y_test_dropoffs, y_pred_dropoffs)\n",
    "\n",
    "#show results\n",
    "res = pd.DataFrame({'Actual_Pickups': y_test_pickups, 'Predicted_Pickups': y_pred_pickups, 'Actual_Dropoffs': y_test_dropoffs, 'Predicted_Dropoffs': y_pred_dropoffs})\n",
    "print('r2 score for pickups:', r2_pickups)\n",
    "print('r2 score for dropoffs:', r2_dropoffs)\n",
    "print('mse for pickups:', mse_pickups)\n",
    "print('mse for dropoffs:', mse_dropoffs)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f83aa",
   "metadata": {},
   "source": [
    "# Section 3 - Exploratory Component:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8b28b",
   "metadata": {},
   "source": [
    "Here we some different ideas (We are not sure what to chose yet):\n",
    "\n",
    "One idea would be to examine how weather conditions, particularly precipitation, affects Citi Bike ridership in New York. By extending the dataset with weather data, we would aim to determine if there is a correlation between precipitation and the number of bike rides. This analysis will provide insights into whether rainy days discourage users from utilizing the bike-sharing system.\n",
    "\n",
    "Another idea would be to build a decision tree model to predict bike usage likelihood based on user demographics, including gender, age, and subscription status. The model will classify users into usage categories, helping identify demographic factors that influence bike usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c538d",
   "metadata": {},
   "source": [
    "# Section 4 - Conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af495d98",
   "metadata": {},
   "source": [
    "No conclusions yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41277f6b",
   "metadata": {},
   "source": [
    "Progress so far (milestone1):\n",
    "\n",
    "We showed a short introduction of the data as well as some visualization for the different features. We found some interesting inferences from the data such as the demographic and trip durations over months/hours.\n",
    "\n",
    "We began the predictive section by performing clustering. Initially started offtrying to figure out the ideal k value using the elmow graph, but due to lack of computation power ,we could not complete it. \n",
    "We use the k value as 20 ( as specified in the project descriptions) directly and identified 20 clusters and found that cluster 1 had the highest trip duration.\n",
    "\n",
    "Note: More work needs to be done in the exploratory section.\n",
    "Data cleaning was not really required so far.\n",
    "The data should also be cleaned a bit more ( remove outliers and missing values) before the predictive section is done further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace720e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
